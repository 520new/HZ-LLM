import os

os.environ["HF_ENDPOINT"] = "https://hf-mirror.com"
import matplotlib

matplotlib.rc("font", family='Microsoft YaHei')
import re
import util
import random
import argparse
import pre_classifier
from models import HGCF_ZSL
import classifier_with_class_norm as classifier
from sklearn.neighbors import KNeighborsClassifier
from models import MultiModalGMVAE, CrossModalAlignmentLoss, DistributionAlignmentLoss, Encoder_Visual, Decoder_Visual
import torch
import torch.nn as nn
import torch.optim as optim
import torch.autograd as autograd
from torch.autograd import Variable
import torch.backends.cudnn as cudnn
import torch.nn.functional as F
import numpy as np

try:
    # åªä½¿ç”¨ Qwen3-VL-8B æ¨¡å‹
    from transformers import Qwen3VLForConditionalGeneration, AutoProcessor

    VL_MODEL_AVAILABLE = True
    print("âœ… ä½¿ç”¨ Qwen3-VL-8B æ¨¡å‹")
except ImportError as e:
    print(f"âš ï¸ Qwen3-VL-8B æ¨¡å‹å¯¼å…¥å¤±è´¥: {e}")
    VL_MODEL_AVAILABLE = False

parser = argparse.ArgumentParser()
parser.add_argument('--dataset', default='CUB', help='dataset for zsl dataset')
parser.add_argument('--syn_num', type=int, default=2000, help='number features to generate per class')  # å¢åŠ ç”Ÿæˆæ ·æœ¬æ•°
parser.add_argument('--nepoch', type=int, default=100, help='number of epochs to train for')
parser.add_argument('--attSize', type=int, default=312, help='size of semantic features')
parser.add_argument('--nz', type=int, default=312, help='size of the latent z vector')
parser.add_argument('--lambda1', type=float, default=10, help='gradient penalty regularizer, following WGAN-GP')
parser.add_argument('--use_hgcf', action='store_true', default=True, help='use HGCF model')
parser.add_argument('--hgcf_lr', type=float, default=0.001, help='learning rate for HGCF')
parser.add_argument('--hgcf_dim', type=int, default=50, help='embedding dimension for HGCF')
parser.add_argument('--lr', type=float, default=0.001, help='learning rate to train GANs ')
parser.add_argument('--classifier_lr', type=float, default=0.0005, help='learning rate to train softmax classifier')
parser.add_argument('--cls_weight', type=float, default=1.0, help='weight of the classification loss')
parser.add_argument('--nclass_all', type=int, default=200, help='number of all classes')
parser.add_argument('--gen_param', type=float, default=1.0, help='proto param 1')
parser.add_argument('--REG_W_LAMBDA', type=float, default=0.0004, help='regularization param')
parser.add_argument('--gzsl', action='store_true', default=True, help='enable generalized zero-shot learning')
parser.add_argument('--final_classifier', default='softmax', help='softmax or knn')
parser.add_argument('--manualSeed', type=int, default=None, help='manual seed')
parser.add_argument('--critic_iter', type=int, default=5, help='critic iteration, following WGAN-GP')
parser.add_argument('--ngh', type=int, default=4096, help='size of the hidden units in generator')
parser.add_argument('--ndh', type=int, default=4096, help='size of the hidden units in discriminator')
parser.add_argument('--resSize', type=int, default=2048, help='size of visual features')
parser.add_argument('--batch_size', type=int, default=128, help='input batch size')
parser.add_argument('--beta1', type=float, default=0.5, help='beta1 for adam. default=0.5')
parser.add_argument('--dataroot', default='./datasets', help='path to dataset')
parser.add_argument('--image_embedding', default='res101')
parser.add_argument('--class_embedding', default='att')
parser.add_argument('--cuda', action='store_true', default=True, help='enables cuda')
parser.add_argument('--ngpu', type=int, default=0, help='number of GPUs to use')
parser.add_argument('--pretrain_classifier', default='', help="path to pretrain classifier (to continue training)")
parser.add_argument('--netG', default='', help="path to netG (to continue training)")
parser.add_argument('--netD', default='', help="path to netD (to continue training)")

# ========== æ–°å¢ï¼šGMVAE ç›¸å…³å‚æ•° ==========
parser.add_argument('--num_clusters', type=int, default=10, help='number of Gaussian mixtures in GM-VAE')
parser.add_argument('--z_dim', type=int, default=312, help='size of the latent z vector for GMVAE')
parser.add_argument('--gmvae_lr', type=float, default=0.0001, help='learning rate for GMVAE')
parser.add_argument('--temp', type=float, default=0.5, help='temperature for Gumbel-softmax')

# ========== ä¿®æ”¹åçš„å¤§æ¨¡å‹ç›¸å…³å‚æ•° ==========
parser.add_argument('--use_vl_model', action='store_true', default=True, help='ä½¿ç”¨è§†è§‰è¯­è¨€å¤§æ¨¡å‹å¢å¼ºå±æ€§')
parser.add_argument('--vl_model_alpha', type=float, default=0.7, help='å¤§æ¨¡å‹å±æ€§å¢å¼ºæƒé‡')
parser.add_argument('--vl_model_name', type=str, default='Qwen/Qwen3-VL-8B-Instruct', help='è§†è§‰è¯­è¨€å¤§æ¨¡å‹åç§°')
parser.add_argument('--vl_max_tokens', type=int, default=131072, help='å¤§æ¨¡å‹ç”Ÿæˆçš„æœ€å¤§tokenæ•°')
# ========== GMVAE å‚æ•°ç»“æŸ ==========

parser.add_argument('--lambda_cm', type=float, default=1.0, help='weight for cross-modal alignment loss')
parser.add_argument('--lambda_d', type=float, default=1.0, help='weight for distribution alignment loss')

# param init
opt = parser.parse_args()

# æ·»åŠ  device å±æ€§
opt.device = torch.device('cuda' if opt.cuda else 'cpu')

# ä» config.py å¯¼å…¥å¹¶ä½¿ç”¨é»˜è®¤å€¼
try:
    from config import config_args

    for key, (default_value, description) in config_args.items():
        if not hasattr(opt, key):
            setattr(opt, key, default_value)
except ImportError:
    print("âš ï¸ config.py not found, using default parameters")

torch.cuda.set_device(opt.ngpu)
if opt.manualSeed is None:
    opt.manualSeed = random.randint(1, 10000)
print("Random Seed: ", opt.manualSeed)
random.seed(opt.manualSeed)
torch.manual_seed(opt.manualSeed)
if opt.cuda:
    torch.cuda.manual_seed_all(opt.manualSeed)
cudnn.benchmark = True
if torch.cuda.is_available() and not opt.cuda:
    print("WARNING: You have a CUDA device, so you should probably run with --cuda")


def init_vl_model(opt):
    """åˆå§‹åŒ–è§†è§‰è¯­è¨€å¤§æ¨¡å‹ - åªä½¿ç”¨Qwen3-VL-8B"""
    if not VL_MODEL_AVAILABLE:
        print("âš ï¸ å¤§æ¨¡å‹ç»„ä»¶ä¸å¯ç”¨ï¼Œè·³è¿‡åˆå§‹åŒ–")
        return None, None

    if not opt.use_vl_model:
        print("âš ï¸ å¤§æ¨¡å‹åŠŸèƒ½å·²ç¦ç”¨")
        return None, None

    try:
        print("ğŸš€ åˆå§‹åŒ– Qwen3-VL-8B æ¨¡å‹...")

        # ä½¿ç”¨ Qwen3-VL-8B æ¨¡å‹
        processor = AutoProcessor.from_pretrained("Qwen/Qwen3-VL-8B-Instruct")
        model = Qwen3VLForConditionalGeneration.from_pretrained(
            "Qwen/Qwen3-VL-8B-Instruct",
            torch_dtype=torch.bfloat16,
            device_map="auto",
            trust_remote_code=True
        )

        # ç¡®ä¿æ¨¡å‹åœ¨GPUä¸Š
        if hasattr(model, 'device'):
            if model.device.type != 'cuda':
                model = model.cuda()
        else:
            model = model.cuda()

        print("âœ… Qwen3-VL-8B æ¨¡å‹åˆå§‹åŒ–æˆåŠŸå¹¶å·²åŠ è½½åˆ°GPU")
        model.eval()
        return model, processor

    except Exception as e:
        print(f"âŒ Qwen3-VL-8B æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None, None


def extract_attributes_with_vl_model(visual_features, batch_size, model, processor, opt):
    """ä½¿ç”¨æœ¬åœ°éƒ¨ç½²çš„Qwen3-VL-8Bæ¨¡å‹åŸºäºç±»åˆ«åç§°æ‰¾åˆ°æœ€å…·åˆ¤åˆ«æ€§çš„å±æ€§"""
    try:
        # è¯»å–ç±»åˆ«åç§°å¹¶æ¸…ç†æ ¼å¼
        class_names = []
        with open('./datasets/CUB/classes.txt', 'r') as f:
            for line in f:
                parts = line.strip().split(' ', 1)
                if len(parts) == 2:
                    # æ¸…ç†ç±»åˆ«åç§°æ ¼å¼ï¼šä» "001.Black_footed_Albatross" æå– "Black footed Albatross"
                    raw_name = parts[1]
                    # ç§»é™¤æ•°å­—å‰ç¼€å’Œç‚¹å·
                    cleaned_name = re.sub(r'^\d+\.', '', raw_name)
                    # å°†ä¸‹åˆ’çº¿æ›¿æ¢ä¸ºç©ºæ ¼
                    cleaned_name = cleaned_name.replace('_', ' ')
                    class_names.append(cleaned_name)

        # è¯»å–å±æ€§åç§°
        attr_names = []
        with open('./datasets/CUB/attributes.txt', 'r') as f:
            for line in f:
                parts = line.strip().split(' ', 1)
                if len(parts) == 2:
                    attr_names.append(parts[1])

        # è¯»å–å›¾åƒå±æ€§æ ‡ç­¾ï¼Œæ„å»ºç±»åˆ«-å±æ€§æ˜ å°„
        class_attributes = {}
        with open('./datasets/CUB/image_attribute_labels.txt', 'r') as f:
            for line in f:
                parts = line.strip().split()
                if len(parts) >= 4:
                    image_id = int(parts[0])
                    attr_id = int(parts[1])
                    is_present = int(parts[2])

                    # æ˜ å°„å›¾åƒIDåˆ°ç±»åˆ«IDï¼ˆCUBæ•°æ®é›†ä¸­å‰4ä½æ•°å­—æ˜¯ç±»åˆ«IDï¼‰
                    class_id = (image_id - 1) // 10  # å‡è®¾æ¯ä¸ªç±»åˆ«æœ‰10å¼ å›¾åƒ

                    if is_present == 1 and attr_id <= len(attr_names):
                        if class_id not in class_attributes:
                            class_attributes[class_id] = set()
                        class_attributes[class_id].add(attr_id)

        # è·å–å½“å‰å¤„ç†çš„ç±»åˆ«åˆ—è¡¨
        current_classes = []
        if hasattr(data, 'seenclasses'):
            current_classes = data.seenclasses.cpu().numpy()
        elif hasattr(data, 'unseenclasses'):
            current_classes = data.unseenclasses.cpu().numpy()
        else:
            current_classes = np.arange(len(class_names))

        enhanced_attributes = []
        processed_count = 0

        for i in range(min(batch_size, len(current_classes))):
            try:
                # è·å–çœŸå®çš„ç±»åˆ«ID
                real_class_id = current_classes[i]
                class_name = class_names[real_class_id]
                print(f"\nğŸ” åˆ†æç±»åˆ« {real_class_id}: '{class_name}'")

                # è·å–è¯¥ç±»åˆ«çš„æ‰€æœ‰å±æ€§
                all_attrs = []
                if real_class_id in class_attributes:
                    for attr_id in class_attributes[real_class_id]:
                        if attr_id < len(attr_names):
                            all_attrs.append(attr_names[attr_id])

                # å¦‚æœæ²¡æœ‰æ‰¾åˆ°å±æ€§ï¼Œä½¿ç”¨data.attributeä½œä¸ºåå¤‡
                if not all_attrs and hasattr(data, 'attribute') and data.attribute is not None:
                    if real_class_id < len(data.attribute):
                        class_attr_vector = data.attribute[real_class_id]
                        # æ‰¾å‡ºå€¼è¾ƒé«˜çš„å±æ€§
                        for attr_idx in range(len(class_attr_vector)):
                            if class_attr_vector[attr_idx] > 0.5 and attr_idx < len(attr_names):
                                all_attrs.append(attr_names[attr_idx])

                print(f"ğŸ“Š æ‰¾åˆ° {len(all_attrs)} ä¸ªç›¸å…³å±æ€§")

                # æ„å»ºåˆ¤åˆ«æ€§å±æ€§åˆ†ææç¤ºè¯
                all_attrs_str = "\n".join([f"- {attr}" for attr in all_attrs[:30]])  # é™åˆ¶æ˜¾ç¤ºæ•°é‡
                if len(all_attrs) > 30:
                    all_attrs_str += f"\n- ... ç­‰{len(all_attrs)}ä¸ªå±æ€§"

                analysis_prompt = f"""
                ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„é¸Ÿç±»å­¦å®¶ã€‚è¯·åˆ†æé¸Ÿç±»"{class_name}"ï¼Œä»ä»¥ä¸‹å±æ€§ä¸­æ‰¾å‡º3-8ä¸ªæœ€å…·åˆ¤åˆ«æ€§çš„å±æ€§ï¼Œæ ¹æ®æ‰¾åˆ°çš„åˆ¤åˆ«æ€§å±æ€§ï¼Œæ„é€ é¸Ÿç±»"{class_name}"ä¸åˆ¤åˆ«æ€§å±æ€§çš„graphã€‚

                å¯ç”¨çš„å±æ€§åˆ—è¡¨ï¼š
                {chr(10).join([f"- {attr}" for attr in all_attrs[:30]])}

                ä¸¥æ ¼æŒ‡ä»¤ï¼š
                1. åªè¾“å‡ºå±æ€§åç§°ï¼Œæ¯è¡Œä¸€ä¸ª
                2. å±æ€§åç§°å¿…é¡»ä»ä¸Šé¢çš„å¯ç”¨å±æ€§åˆ—è¡¨ä¸­ç²¾å‡†å¤åˆ¶
                3. å¿…é¡»é€‰æ‹©æœ€å…·åˆ¤åˆ«æ€§çš„å±æ€§
                4. ç»å¯¹ç¦æ­¢æ·»åŠ ä»»ä½•è§£é‡Šã€æè¿°ã€ç¤ºä¾‹ã€åºå·ã€æé—®æˆ–å…¶ä»–æ–‡æœ¬
                5. ç»å¯¹ç¦æ­¢è¾“å‡ºç±»ä¼¼"æœ‰è¯¯å—ï¼Ÿ"ã€"å‚è€ƒç­”æ¡ˆ"ã€"ä»¥ä¸‹æç¤º"ç­‰æ— å…³å†…å®¹
                6. ç»å¯¹ç¦æ­¢è¾“å‡ºä»»ä½•ä¸­æ–‡æ–‡æœ¬
                7. ç»å¯¹ç¦æ­¢è¾“å‡ºé‡å¤çš„å±æ€§åç§°

                è¿è§„ç¤ºä¾‹ï¼ˆç¦æ­¢è¾“å‡ºè¿™äº›ï¼‰ï¼š
                - "æœ‰è¯¯å—ï¼Ÿ"
                - "å‚è€ƒç­”æ¡ˆ"
                - "ä»¥ä¸‹æç¤º"
                - "1. has_bill_shape::needle" (ä¸è¦æœ‰åºå·)
                - ä»»ä½•ä¸­æ–‡è§£é‡Š

                æ­£ç¡®è¾“å‡ºæ ¼å¼ï¼š
                has_bill_shape::needle
                has_upperparts_color::brown  
                has_underparts_color::blue
                has_breast_color::blue
                has_back_color::blue
                has_tail_shape::forked_tail
                has_head_pattern::plain

                ç°åœ¨å¼€å§‹è¾“å‡ºï¼Œä¸¥æ ¼éµå®ˆä¸Šè¿°è¦æ±‚ï¼š
                """
                # è°ƒç”¨æœ¬åœ°Qwen3-VL-8Bæ¨¡å‹
                inputs = processor(
                    text=analysis_prompt,
                    return_tensors="pt",
                    padding=True,
                    truncation=True,
                    max_length=131072
                )

                if opt.cuda:
                    inputs = {k: v.cuda() for k, v in inputs.items()}

                # ç”Ÿæˆåˆ¤åˆ«æ€§å±æ€§
                with torch.no_grad():
                    generated_ids = model.generate(
                        **inputs,
                        max_new_tokens=4096,
                        do_sample=True,
                        temperature=0.7,
                        top_p=0.9,
                        pad_token_id=processor.tokenizer.eos_token_id
                    )

                # è§£ç ç”Ÿæˆçš„æ–‡æœ¬
                response = processor.decode(generated_ids[0], skip_special_tokens=True)

                # æå–æ¨¡å‹çš„å®é™…å›å¤
                if analysis_prompt in response:
                    response = response.split(analysis_prompt)[-1].strip()

                # è§£æåˆ¤åˆ«æ€§å±æ€§
                discriminative_attrs = []
                for line in response.split('\n'):
                    line = line.strip()

                    # è·³è¿‡ç©ºè¡Œå’Œæ³¨é‡Šè¡Œ
                    if not line or line.startswith('#') or line.startswith('//'):
                        continue

                    # è·³è¿‡åŒ…å«ä¸­æ–‡çš„è¡Œ
                    if any('\u4e00' <= char <= '\u9fff' for char in line):
                        continue

                    # è·³è¿‡åŒ…å«è¿è§„å…³é”®è¯çš„è¡Œ
                    skip_keywords = ['æœ‰è¯¯å—', 'å‚è€ƒç­”æ¡ˆ', 'ä»¥ä¸‹æç¤º', 'æç¤º', 'ç¤ºä¾‹', 'æ³¨æ„', 'è¦æ±‚', 'ä¸¥æ ¼æŒ‡ä»¤', 'è¿è§„ç¤ºä¾‹', 'æ­£ç¡®è¾“å‡ºæ ¼å¼']
                    if any(keyword in line for keyword in skip_keywords):
                        continue

                    # æ¸…ç†å±æ€§åç§°ï¼šç§»é™¤åºå·å’Œå¤šä½™ç¬¦å·
                    cleaned_line = re.sub(r'^\d+\.\s*', '', line)  # ç§»é™¤ "1. " æ ¼å¼çš„åºå·
                    cleaned_line = re.sub(r'^-\s*', '', cleaned_line)  # ç§»é™¤ "- " æ ¼å¼çš„ç¬¦å·
                    cleaned_line = cleaned_line.strip()

                    # åªä¿ç•™åŒ…å« "::" çš„åˆæ³•å±æ€§æ ¼å¼
                    if '::' in cleaned_line or 'has_' in cleaned_line:
                        discriminative_attrs.append(cleaned_line)

                # è¾“å‡ºåˆ¤åˆ«æ€§å±æ€§
                print(f"âœ… ç±»åˆ« '{class_name}' çš„åˆ¤åˆ«æ€§å±æ€§:")
                for j, attr in enumerate(discriminative_attrs[:8], 1):  # é™åˆ¶æœ€å¤š8ä¸ª
                    print(f"   {j}. {attr}")

                # å¦‚æœæ¨¡å‹æ²¡æœ‰æ‰¾åˆ°è¶³å¤Ÿçš„åˆ¤åˆ«æ€§å±æ€§ï¼Œä½¿ç”¨é¢‘ç‡æœ€é«˜çš„å±æ€§ä½œä¸ºåå¤‡
                if len(discriminative_attrs) < 3:
                    # ä½¿ç”¨å‰å‡ ä¸ªå±æ€§ä½œä¸ºè¡¥å……
                    backup_attrs = all_attrs[:min(7, len(all_attrs))]
                    added_count = 0
                    for attr in backup_attrs:
                        if attr not in discriminative_attrs:
                            discriminative_attrs.append(attr)
                            added_count += 1
                            print(f"   {added_count}. {attr}")

                # å°†åˆ¤åˆ«æ€§å±æ€§è½¬æ¢ä¸ºå±æ€§å‘é‡
                attr_vector = torch.zeros(opt.attSize, device=opt.device, dtype=torch.bfloat16)

                # åŸºäºåˆ¤åˆ«æ€§å±æ€§è®¾ç½®å±æ€§å€¼
                for attr_name in discriminative_attrs:
                    # åœ¨å±æ€§åç§°åˆ—è¡¨ä¸­æŸ¥æ‰¾åŒ¹é…
                    for attr_idx, full_attr_name in enumerate(attr_names):
                        if attr_idx >= opt.attSize:
                            break

                        # æ£€æŸ¥å±æ€§åç§°æ˜¯å¦åŒ…å«å…³é”®è¯
                        if attr_name.lower() in full_attr_name.lower():
                            # è®¾ç½®è¾ƒé«˜çš„æƒé‡
                            attr_vector[attr_idx] = max(attr_vector[attr_idx], 0.9)
                            break
                    else:
                        # å¦‚æœæ²¡æœ‰ç²¾ç¡®åŒ¹é…ï¼Œå°è¯•éƒ¨åˆ†åŒ¹é…
                        for attr_idx, full_attr_name in enumerate(attr_names):
                            if attr_idx >= opt.attSize:
                                break
                            # æ£€æŸ¥æ˜¯å¦åŒ…å«å…³é”®éƒ¨åˆ†
                            keywords = attr_name.lower().split()
                            if any(keyword in full_attr_name.lower() for keyword in keywords if len(keyword) > 3):
                                attr_vector[attr_idx] = max(attr_vector[attr_idx], 0.6)

                # ç‰¹åˆ«å¢å¼ºåŸå§‹æ•°æ®ä¸­å­˜åœ¨çš„å±æ€§çš„æƒé‡
                for attr_id in class_attributes.get(real_class_id, []):
                    if attr_id < opt.attSize:
                        attr_vector[attr_id] = max(attr_vector[attr_id], 0.9)

                # ç¡®ä¿å±æ€§å‘é‡åœ¨åˆç†èŒƒå›´å†…
                attr_vector = torch.clamp(attr_vector, 0.0, 1.0)

                # å¦‚æœå±æ€§å‘é‡ä»ç„¶å¾ˆå¼±ï¼Œä½¿ç”¨ä¸­ç­‰å¼ºåº¦å¢å¼º
                if torch.max(attr_vector) < 0.3:
                    print("âš ï¸ å±æ€§å‘é‡å¼ºåº¦ä¸è¶³ï¼Œä½¿ç”¨ä¸­ç­‰å¼ºåº¦å¢å¼º")
                    # éšæœºé€‰æ‹©ä¸€äº›å±æ€§å¢å¼º
                    indices = torch.randperm(min(10, opt.attSize))[:5]
                    attr_vector[indices] = 0.5

                noise = torch.randn_like(attr_vector) * 0.01
                attr_vector = torch.clamp(attr_vector + noise, 0.0, 1.0)

                enhanced_attributes.append(attr_vector)
                processed_count += 1

                print(f"âœ… ç±»åˆ« {real_class_id} çš„åˆ¤åˆ«æ€§å±æ€§åˆ†æå®Œæˆ")

            except Exception as e:
                print(f"âš ï¸ ç±»åˆ« {real_class_id} å¤„ç†å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                # ä½¿ç”¨ä¸­ç­‰å¼ºåº¦å±æ€§ä½œä¸ºåå¤‡
                default_attr = torch.ones(opt.attSize, device=opt.device) * 0.5
                enhanced_attributes.append(default_attr)

        # å¦‚æœå¤„ç†çš„æ ·æœ¬å°‘äºbatch_sizeï¼Œä½¿ç”¨åˆç†çš„æ‰©å±•ç­–ç•¥
        while len(enhanced_attributes) < batch_size:
            if enhanced_attributes:
                last_attr = enhanced_attributes[-1].clone()
                variation = torch.randn_like(last_attr) * 0.03
                new_attr = torch.clamp(last_attr + variation, 0.0, 1.0)
                enhanced_attributes.append(new_attr)
            else:
                enhanced_attributes.append(torch.ones(opt.attSize, device=opt.device) * 0.5)

        result = torch.stack(enhanced_attributes)
        return result

    except Exception as e:
        print(f"âŒ åˆ¤åˆ«æ€§å±æ€§åˆ†æå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        default_attrs = torch.ones(batch_size, opt.attSize, device=opt.device) * 0.5
        return default_attrs


# load data
data = util.DATA_LOADER(opt)
print("Training samples: ", data.ntrain)  # 19832

# initialize HGCF model for ZSL
netG = HGCF_ZSL(opt)

print("ğŸš€ åˆå§‹åŒ–å¤šæ¨¡æ€GMVAE...")
multi_modal_gmvae = MultiModalGMVAE(opt)
if opt.cuda:
    multi_modal_gmvae = multi_modal_gmvae.cuda()
    print("âœ… å¤šæ¨¡æ€GMVAEå·²ç§»åŠ¨åˆ°GPU")

# å°†å¤šæ¨¡æ€GMVAEæ·»åŠ åˆ°netGä¸­ä»¥ä¾¿è®¿é—®
netG.multi_modal_gmvae = multi_modal_gmvae

# æ£€æŸ¥GMVAEç»„ä»¶æ˜¯å¦æˆåŠŸåˆ›å»º
if hasattr(netG, 'use_gmvae') and netG.use_gmvae:
    if hasattr(netG, 'gmvae_optimizer'):
        print("GMVAE optimizer successfully created")
    else:
        print("Warning: GMVAE optimizer not created, disabling GMVAE")
        netG.use_gmvae = False

if opt.netG != '':
    netG.load_state_dict(torch.load(opt.netG))

# åˆå§‹åŒ–å¤§æ¨¡å‹
vl_model, vl_processor = init_vl_model(opt)
if vl_model is not None:
    # å†æ¬¡ç¡®ä¿Qwen3-VL-8Bæ¨¡å‹åœ¨GPUä¸Š
    if hasattr(vl_model, 'device'):
        if vl_model.device.type != 'cuda':
            vl_model = vl_model.cuda()
            print("âœ… Qwen3-VL-8Bæ¨¡å‹å·²å¼ºåˆ¶ç§»åŠ¨åˆ°GPU")
    else:
        vl_model = vl_model.cuda()
        print("âœ… Qwen3-VL-8Bæ¨¡å‹å·²ç§»åŠ¨åˆ°GPU")
    opt.vl_model = vl_model
    opt.vl_processor = vl_processor

# ç¡®ä¿æ‰€æœ‰æ¨¡å‹éƒ½åœ¨GPUä¸Š
if opt.cuda:
    netG = netG.cuda()
    if hasattr(opt, 'vl_model') and opt.vl_model is not None:
        # ç¡®ä¿Qwen2.5-VLæ¨¡å‹åœ¨GPUä¸Š
        if hasattr(opt.vl_model, 'device'):
            if opt.vl_model.device.type != 'cuda':
                opt.vl_model = opt.vl_model.cuda()
        else:
            opt.vl_model = opt.vl_model.cuda()
    print("âœ… æ‰€æœ‰æ¨¡å‹å·²ç§»åŠ¨åˆ°GPU")

# classification loss, Equation (4) of the paper
cls_criterion = nn.NLLLoss()
input_res = torch.FloatTensor(opt.batch_size, opt.resSize)
input_att = torch.FloatTensor(opt.batch_size, opt.attSize)
noise = torch.FloatTensor(opt.batch_size, opt.nz)
input_label = torch.LongTensor(opt.batch_size)  # [64,]

if opt.cuda:
    # netG.cuda()  # è¿™è¡Œå·²ç»åœ¨ä¸Šé¢çš„ifè¯­å¥ä¸­æ‰§è¡Œäº†
    input_res = input_res.cuda()
    input_att = input_att.cuda()
    noise = noise.cuda()
    cls_criterion.cuda()
    input_label = input_label.cuda()


def sample():
    batch_feature, batch_label, batch_att = data.next_batch(opt.batch_size)  # s label is normal label based 0
    input_res.copy_(batch_feature)
    input_att.copy_(batch_att)
    input_label.copy_(util.map_label(batch_label, data.seenclasses))  # map normal label into 0-39


def compute_multi_modal_loss(visual_features, attributes, netG):
    """è®¡ç®—å¤šæ¨¡æ€æŸå¤± - ä¿®å¤ï¼šä¸è¿›è¡Œåå‘ä¼ æ’­ï¼Œåªè¿”å›æŸå¤±å€¼"""
    if not hasattr(netG, 'multi_modal_gmvae') or netG.multi_modal_gmvae is None:
        return 0, {}

    try:
        # ä¿®å¤ï¼šç”Ÿæˆå™ªå£°å¹¶ä¼ å…¥forwardæ–¹æ³•
        batch_size = visual_features.size(0)
        noise = torch.randn(batch_size, netG.multi_modal_gmvae.opt.nz).to(visual_features.device)

        losses = netG.multi_modal_gmvae(visual_features, attributes, noise)
        total_loss = losses['total_loss']

        # æ‰“å°è¯¦ç»†æŸå¤±ä¿¡æ¯
        print(f"MultiModal Loss - Total: {total_loss:.4f}, "
              f"Recon: {losses['recon_loss']:.4f}, "
              f"KL: {losses['kl_loss']:.4f}, "
              f"CrossModal: {losses['cross_modal_loss']:.4f}, "
              f"Distribution: {losses['distribution_loss']:.4f}")

        return total_loss, losses
    except Exception as e:
        print(f"å¤šæ¨¡æ€æŸå¤±è®¡ç®—å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return 0, {}


def generate_syn_feature(netG, classes, attribute, num):
    nclass = classes.size(0)
    print(f"Generating {num} samples for each of {nclass} classes")

    syn_feature = torch.FloatTensor(nclass * num, netG.resSize)
    syn_label = torch.LongTensor(nclass * num)

    netG.eval()
    with torch.no_grad():
        for i in range(nclass):
            iclass = classes[i]
            iclass_att = attribute[iclass].unsqueeze(0)  # [1, attSize]

            # é‡å¤å±æ€§ç‰¹å¾æ¥ç”Ÿæˆå¤šä¸ªæ ·æœ¬
            syn_att = iclass_att.repeat(num, 1)  # [num, attSize]

            # ç”Ÿæˆéšæœºè§†è§‰ç‰¹å¾ä½œä¸ºåŸºç¡€
            base_features = torch.randn(num, netG.resSize)
            if netG.device.type == 'cuda':
                base_features = base_features.cuda()
                syn_att = syn_att.cuda()

            # ä½¿ç”¨æ¨¡å‹ç”Ÿæˆç‰¹å¾
            try:
                # å°è¯•ä½¿ç”¨æ¨¡å‹çš„ç”Ÿæˆæ–¹æ³•
                if hasattr(netG, 'generate_features'):
                    class_tensor = torch.tensor([iclass], dtype=torch.long)
                    if netG.device.type == 'cuda':
                        class_tensor = class_tensor.cuda()

                    generated = netG.generate_features(class_tensor, num, use_gmvae=True)

                    # ç¡®ä¿ç»´åº¦åŒ¹é…
                    if generated.size(1) != netG.resSize:
                        print(
                            f"Warning: Generated feature dimension {generated.size(1)} doesn't match expected {netG.resSize}")
                        # ä½¿ç”¨ç®€å•çš„æŠ•å½±å±‚
                        if not hasattr(netG, 'feature_adapter'):
                            netG.feature_adapter = nn.Linear(generated.size(1), netG.resSize)
                            if netG.device.type == 'cuda':
                                netG.feature_adapter = netG.feature_adapter.cuda()
                        generated = netG.feature_adapter(generated)
                else:
                    # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨å±æ€§ç‰¹å¾é€šè¿‡ä¸€ä¸ªç®€å•çš„MLPç”Ÿæˆè§†è§‰ç‰¹å¾
                    if not hasattr(netG, 'feature_generator'):
                        # åˆ›å»ºä¸€ä¸ªç®€å•çš„ç‰¹å¾ç”Ÿæˆå™¨
                        netG.feature_generator = nn.Sequential(
                            nn.Linear(netG.attSize, 512),
                            nn.ReLU(),
                            nn.Linear(512, 1024),
                            nn.ReLU(),
                            nn.Linear(1024, netG.resSize)
                        )
                        if netG.device.type == 'cuda':
                            netG.feature_generator = netG.feature_generator.cuda()

                    # æ·»åŠ ä¸€äº›å™ªå£°
                    noise = torch.randn(num, netG.attSize)
                    if netG.device.type == 'cuda':
                        noise = noise.cuda()
                    generator_input = syn_att + noise * 0.01
                    generated = netG.feature_generator(generator_input)

                # ç¡®ä¿ç”Ÿæˆçš„æ ·æœ¬æ•°é‡æ­£ç¡®
                if generated.size(0) > num:
                    generated = generated[:num]
                elif generated.size(0) < num:
                    # å¦‚æœç”Ÿæˆçš„æ•°é‡ä¸å¤Ÿï¼Œå¤åˆ¶æœ€åä¸€ä¸ªæ ·æœ¬
                    padding = generated[-1:].repeat(num - generated.size(0), 1)
                    generated = torch.cat([generated, padding], dim=0)

                # ç§»åŠ¨åˆ°CPUå¹¶å­˜å‚¨
                generated_cpu = generated.data.cpu()
                syn_feature.narrow(0, i * num, num).copy_(generated_cpu)
                syn_label.narrow(0, i * num, num).fill_(iclass)

                # æ¸…ç†GPUå†…å­˜
                if netG.device.type == 'cuda':
                    torch.cuda.empty_cache()

            except Exception as e:
                print(f"Error generating features for class {iclass}: {e}")
                # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨éšæœºç‰¹å¾
                random_features = torch.randn(num, netG.resSize)
                syn_feature.narrow(0, i * num, num).copy_(random_features)
                syn_label.narrow(0, i * num, num).fill_(iclass)

    return syn_feature, syn_label


def map_label(label, classes):
    mapped_label = torch.LongTensor(label.size())
    for i in range(classes.size(0)):
        mapped_label[label == classes[i]] = i
    return mapped_label


# setup optimizer for HGCF
optimizerG = optim.Adam(netG.parameters(), lr=0.001, weight_decay=0.0005)  # é™ä½å­¦ä¹ ç‡ï¼Œå¢åŠ æƒé‡è¡°å‡

# æ·»åŠ å­¦ä¹ ç‡è°ƒåº¦å™¨
scheduler = torch.optim.lr_scheduler.StepLR(optimizerG, step_size=100, gamma=0.5)


def compute_per_class_acc_gzsl(predicted_label, test_label, target_classes):
    acc_per_class = 0
    for i in target_classes:
        idx = (test_label == i)
        if torch.sum(idx).float() == 0:
            continue
        else:
            acc_per_class += torch.sum(test_label[idx] == predicted_label[idx]).float() / torch.sum(idx).float()
    acc_per_class /= target_classes.size(0)
    return acc_per_class


# train a classifier on seen classes, obtain \theta of Equation (4)
pretrain_cls = pre_classifier.CLASSIFIER(_train_X=data.train_feature,
                                         _train_Y=util.map_label(data.train_label, data.seenclasses),
                                         _nclass=data.seenclasses.size(0), _input_dim=opt.resSize, _cuda=opt.cuda,
                                         _lr=0.001, _beta1=0.5, _nepoch=100, _batch_size=128,
                                         pretrain_classifer=opt.pretrain_classifier)

# freeze the classifier during the optimization
for p in pretrain_cls.model.parameters():  # set requires_grad to False
    p.requires_grad = False

best_H = 0
best_unseen = 0

# æ·»åŠ è¿›åº¦æ¡
from tqdm import tqdm
import time

for epoch in range(opt.nepoch):
    # æ‰“å°epochä¿¡æ¯ - æŒ‰ç…§è¦æ±‚æ ¼å¼
    print(f"EP[{epoch}/{opt.nepoch}]", "*" * 85)

    # è®¡ç®—æ€»æ‰¹æ¬¡æ•°
    total_batches = (data.ntrain + opt.batch_size - 1) // opt.batch_size

    # åˆ›å»ºæ‰¹æ¬¡è¿›åº¦æ¡ - æŒ‰ç…§è¦æ±‚æ ¼å¼
    pbar = tqdm(total=total_batches, ncols=None,
                bar_format='{percentage:3.0f}%|{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}{postfix}]')

    total_loss = 0
    batch_count = 0

    for i in range(0, data.ntrain, opt.batch_size):
        sample()
        netG.zero_grad()

        input_resv = Variable(input_res)
        input_attv = Variable(input_att)
        input_labelv = Variable(input_label)

        # ========== Qwen3-VL-8Bå¤§æ¨¡å‹å±æ€§å¢å¼ºå¤„ç† ==========
        if opt.use_vl_model and hasattr(opt, 'vl_model') and opt.vl_model is not None:
            try:
                with torch.no_grad():
                    # è·å–å½“å‰batchçš„ç±»åˆ«æ ‡ç­¾
                    batch_classes = data.seenclasses[input_label.cpu()] if hasattr(data,
                                                                                   'seenclasses') else input_label.cpu()

                    enhanced_att = extract_attributes_with_vl_model(
                        input_resv.data,  # ä¿æŒå‚æ•°å…¼å®¹æ€§
                        opt.batch_size,
                        opt.vl_model,
                        opt.vl_processor,
                        opt
                    )

                    if enhanced_att is not None:
                        # èåˆåŸå§‹å±æ€§å’Œå¤§æ¨¡å‹å¢å¼ºå±æ€§
                        input_attv_enhanced = opt.vl_model_alpha * enhanced_att + (
                                1 - opt.vl_model_alpha) * input_attv.data
                        input_attv = Variable(input_attv_enhanced)
                        print("âœ… Qwen3-VL-8Bå±æ€§å¢å¼ºå®Œæˆ")
                    else:
                        print("âš ï¸ Qwen3-VL-8Bå¤„ç†è¿”å›Noneï¼Œä½¿ç”¨åŸå§‹å±æ€§")
            except Exception as e:
                print(f"âš ï¸ Qwen3-VL-8Bå¤„ç†å¼‚å¸¸: {e}, ä½¿ç”¨åŸå§‹å±æ€§")

        print("ğŸ”„ è®¡ç®—GMVAEæŸå¤±...")
        mm_total_loss, mm_losses = compute_multi_modal_loss(input_resv, input_attv, netG)

        # ZSLå‰å‘ä¼ æ’­ - è®¡ç®—ç±»åˆ«ç›¸ä¼¼åº¦
        output = netG(input_resv, input_attv, input_labelv, train_gmvae=False)

        # æ·»åŠ softmaxå½’ä¸€åŒ–ï¼Œå› ä¸ºNLLLosséœ€è¦log probabilities
        log_probs = F.log_softmax(output, dim=1)
        loss = cls_criterion(log_probs, input_labelv)  # ä½¿ç”¨log_softmaxçš„è¾“å‡º

        # æ€»æŸå¤± = ZSLåˆ†ç±»æŸå¤± + å¤šæ¨¡æ€æŸå¤±
        total_combined_loss = loss + mm_total_loss * 0.1  # å¤šæ¨¡æ€æŸå¤±æƒé‡ä¸º0.1

        # åªè¿›è¡Œä¸€æ¬¡åå‘ä¼ æ’­
        total_combined_loss.backward()

        # æ·»åŠ æ¢¯åº¦è£å‰ª
        torch.nn.utils.clip_grad_norm_(netG.parameters(), max_norm=1.0)

        optimizerG.step()

        # æ›´æ–°è¿›åº¦æ¡
        pbar.update(1)
        postfix = {
            "Loss": f"{loss.item():.4f}",
            "MM_Loss": f"{mm_total_loss:.4f}" if mm_total_loss > 0 else "0.0000"
        }
        pbar.set_postfix(postfix)

    pbar.close()

    # æ›´æ–°å­¦ä¹ ç‡
    scheduler.step()

    # æ¯ä¸ªepochç»“æŸåè¿›è¡Œè¯„ä¼°
    netG.eval()
    with torch.no_grad():
        # ç”Ÿæˆæœªè§ç±»åˆ«çš„ç‰¹å¾å¹¶è¯„ä¼°
        try:
            print(f"Starting evaluation for epoch {epoch}")

            # ä½¿ç”¨GMVAEç”Ÿæˆç‰¹å¾
            print("Generating synthetic features...")
            syn_unseen_feature, syn_unseen_label = generate_syn_feature(netG, data.unseenclasses, data.attribute,
                                                                        opt.syn_num)

            print(f"Generated features shape: {syn_unseen_feature.shape}")
            print(f"Generated labels shape: {syn_unseen_label.shape}")

            # æ£€æŸ¥æ•°æ®æœ‰æ•ˆæ€§
            if torch.isnan(syn_unseen_feature).any():
                print("Warning: Generated features contain NaN values")
                syn_unseen_feature = torch.nan_to_num(syn_unseen_feature)

            train_X = torch.cat((data.train_feature, syn_unseen_feature), 0)
            train_Y = torch.cat((data.train_label, syn_unseen_label), 0)

            print(f"Combined training features shape: {train_X.shape}")
            print(f"Combined training labels shape: {train_Y.shape}")

            if opt.gzsl:
                # ä½¿ç”¨classifier_with_class_normä¸­çš„CLASSIFIERï¼Œè°ƒæ•´å‚æ•°
                cls = classifier.CLASSIFIER(
                    train_X, train_Y, data, opt.nclass_all, opt.cuda,
                    _lr=0.001,  # é™ä½å­¦ä¹ ç‡
                    _beta1=0.5,
                    _nepoch=100,  # å¢åŠ è®­ç»ƒè½®æ•°
                    _batch_size=128,  # è°ƒæ•´æ‰¹æ¬¡å¤§å°
                    generalized=True
                )

                # æ ¼å¼åŒ–è¾“å‡ºç»“æœ - æŒ‰ç…§è¦æ±‚æ ¼å¼
                print(f"ZSL results: {cls.zsl_unseen:.4f}")
                print(f"GZSL results: unseen={cls.gzsl_unseen:.4f}, seen={cls.gzsl_seen:.4f}, h={cls.gzsl_H:.4f}")

                if cls.gzsl_H > best_H:
                    best_H = cls.gzsl_H
                    torch.save(netG.state_dict(),
                               './saved_models/HGCF_seen{0}_unseen{1}_H{2}.pth'.format(cls.gzsl_seen, cls.gzsl_unseen,
                                                                                       cls.gzsl_H))
                    print('âœ… GZSLæœ€ä½³æ¨¡å‹å·²ä¿å­˜')

                if cls.zsl_unseen > best_unseen:
                    best_unseen = cls.zsl_unseen
                    torch.save(netG.state_dict(), f'./saved_models/hgcf_zsl_best_unseen{best_unseen:.4f}.pth')
                    print(f'âœ… ZSLæœ€ä½³æ¨¡å‹å·²ä¿å­˜')

        except Exception as e:
            print(f"Error in evaluation: {e}")
            import traceback

            traceback.print_exc()
            continue
    netG.train()